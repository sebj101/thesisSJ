\chapter{DUNE long-baseline analysis}
\label{sec:dune_lbl}

%%% Overall point of this chapter: How do our uncertainties relate to our ability to measure CPV
As covered in \citechap{sec:dune}, DUNE's primary goal is to make a measurement of CP violation (CPV) in the lepton sector.
Secondary to this are other goals such as the determination of the neutrino mass hierarchy and the precision measurement of some of the other parameters governing neutrino oscillations.

Prior to any construction of the experiment, it is important to assess DUNE's eventual sensitivity to both CPV and other oscillation physics.
In order to do this, sensitivity studies must be undertaken using simulated Monte Carlo data, which attempts to represent the data that DUNE is likely to gather during its operational phase.

In order to properly assess these sensitivities, a set of systematic uncertainties is evaluated, covering all parts of the DUNE experiment.
This chapter provides a brief description of these systematic uncertainties and their origins in \citesec{sec:dune_lbl:systs}.

Following on from this, \citesec{sec:dune_lbl:sensitivities} provides a description of the methods used to extract DUNE's sensitivities.
Also in this section, results are presented showing DUNE's sensitivity to both CPV in the lepton sector and the neutrino mass hierarchy.

\section{Summary of DUNE systematic uncertainties}
\label{sec:dune_lbl:systs}

This section gives a summary of the systematic uncertainties used in DUNE's long baseline analysis and where they are derived from.
\citesec{sec:dune_lbl:systs:flux} details the systematics deriving from lack of knowledge about the neutrino beam (commonly referred to as the `flux' systematics).
\citesec{sec:dune_lbl:systs:xsec} gives details of those systematics relating to lack of knowledge surrounding neutrino interactions with matter (commonly referred to as the cross-section systematics).
Finally, \citesec{sec:dune_lbl:systs:det} outlines the systematic uncertainties which derive from the uncertainty surrounding detector effects, for example the reconstructed energies of charged particles in the detector.

\subsection{Flux}
\label{sec:dune_lbl:systs:flux}

Uncertainties in the neutrino beam flux primarily arise from two sources: uncertainties in the production of hadrons by protons striking the beam target and uncertainties in the design parameters of the beam such as the horn currents or positioning (commonly referred to as the `focussing uncertainties').

The focussing uncertainties are evaluated by varying the beam line parameters within their tolerances and observing the resulting changes in the neutrino fluxes.
Hadron production uncertainties are estimated using uncertainties from thin target data experiments such as NA49~\cite{na49} with large uncertainties assigned to those interactions that are not covered by data.

\citefig{fig:fluxUncertainties} shows these uncertainties as a function of neutrino energy for the \numu and \anumu fluxes in both neutrino and antineutrino mode.
These can be compared with the FD neutrino fluxes shown in \citefig{fig:fdFlux}.
One can see that, at nearly all energies, hadron production uncertainties are larger than focussing uncertainties.
The spike in the focussing uncertainties at roughly \SI{5}{\GeV} for right-sign \numu and \anumu results from the uncertainty in the magnetic horn current~\cite{tdrVol2} which is sharply peaked at this point.

\begin{figure}[h]
  \centering
  \includegraphics[width=.8\linewidth]{files/figures/dune_detector/fluxUncertainties}
  \caption[Far detector flux uncertainties for \numu and \anumu]{Far detector \numu and \anumu flux uncertainties as a function of neutrino energy, from~\cite{tdrVol2}. The uncertainties are separated into those resulting from hadron production and those resulting from the focussing uncertainties.}
  \label{fig:fluxUncertainties}
\end{figure}

The flux uncertainties are evaluated by running many simulations with variations of the hadron production and focussing uncertainties mentioned above and then using this information to build a covariance matrix.
This matrix is binned in neutrino energy and flavour and has dimensions of $208 \times 208$ bins.
The matrix is then diagonalised to give 208 principal components, along with their eigenvalues.
The largest 30 of these principal components (when ordered by the size of their eigenvalues) are used as the flux systematic uncertainties.
The eigenvalues rapidly decrease (the 10th principal component has an eigenvalue which is 1\% the size of the 0th component's eigenvalue~\cite{tdrVol2}) and thus this saves on computation time without affecting the result. 
Further details are available in Ref.~\cite{duneFluxUncertainties}.

These flux uncertainties can be compared with those from the T2K experiment, shown in \citefig{fig:t2kFluxUnc}.
The total flux uncertainties in the peak region of the unoscillated flux (a true neutrino energy of about \SI{0.6}{\GeV}) are about 15\%, slightly larger than those expected for DUNE (about 12\% at the flux peak).
The largest uncertainties at \SI{0.6}{\GeV} result from pion and kaon production, similar to DUNE where hadron production uncertainties dominate.
Furthermore, NOvA reports flux uncertainties of 21\% in the peak region of the neutrino flux~\cite{novaFluxUnc}, again larger than those expected by DUNE.
This indicates that DUNE's expected flux uncertainties are similar or slightly smaller than thos of of the T2K experiment.

\begin{figure}[h]
  \centering
  \includegraphics[width=.9\linewidth]{files/figures/dune_lbl/t2kFluxUncertainties}
  \caption[Fractional errors on beam neutrino fluxes in Super-Kamiokande]{Fractional errors on the beam neutrino fluxes in the Super-Kamiokande detector as a function of true neutrino energy, from~\cite{t2kFluxUnc}. The unoscillated neutrino flux peaks at \SI{0.6}{\GeV}. Left: Muon neutrinos. Right: Electron neutrinos.}
  \label{fig:t2kFluxUnc}
\end{figure}


\subsection{Neutrino interaction (cross-section)}
\label{sec:dune_lbl:systs:xsec}

%Uncertainties in the neutrino interaction model come from a variety of sources. 
The primary model used in the DUNE long-baseline analysis is that provided by the chosen neutrino interaction generator, Generates Events for Neutrino Interaction Experiments (GENIE)~\cite{genie}.
The version of GENIE used in the DUNE long-baseline analysis is v2.12.0.

The interaction model takes a neutrino flux and outputs the final state particles produced by said neutrinos interacting with the target medium.
For the most part, these interactions are modelled as factorising the interaction into three parts: an initial nuclear state, the neutrino interaction with a nucleon and the propagation of final state particles through the nucleus.
The systematic uncertainties used in this analysis relate to all three elements of this modelling picture, among other categories.

Many of the systematic uncertainties are included as standard in GENIE, while others are developed specifically for the DUNE long-baseline analysis.
These uncertainties take the form of either continuous weights or discrete model comparisons.
These uncertainties are derived from a variety of sources, including freedoms in theoretical models, current experimental measurements and observed discrepancies between models and experiments.

\subsection{Detector}
\label{sec:dune_lbl:systs:det}

Detector systematics in the DUNE long-baseline analysis primarily take the form of bin-to-bin energy shifts, rather than the weights typically used for the flux and cross-section systematics.
These are expressed as multi-parameter energy scale shifts for various final state particles species and are of the form
\begin{equation}
E_{\alpha,~\text{reco}}' = E_{\alpha,~\text{reco}} \left( p_{0} + p_{1} \sqrt{E_{\alpha,~\text{reco}}} + \frac{p_{2}}{\sqrt{E_{\alpha,~\text{reco}}+0.1}} \right) \, ,
\label{eq:energyResponse}	
\end{equation}
where the $p_{n}$ are allowed to vary in any fits.

\citetab{tab:energyScaleParams} shows the $1\sigma$ values of the $p_{n}$ for each of the particle types.
All of these uncertainties are treated as uncorrelated between the near and far detectors.
This decision is made due to the differences in detector technologies and likely calibration strategies between near and far detectors.

The first term of \citeeq{eq:energyResponse} remains constant with energy while the second and third are dominant at high and low particle energies respectively.
Uncertainties of the kind likely to be represented by the first term are uncertainties in any calibration scale.
An uncertainty represented by the second term is the possible difficulty in reconstructing low energy particles, perhaps due to short tracks in the detector.
Finally, the third term represents those uncertainties which do not affect low energy particles but come to dominate at high energies.
For example, high energy hadrons may scatter inelastically, knocking out neutrons which are very difficult to accurately reconstruct.

The values of the $p_{0}$ (the absolute scale factors) are motivated by those values achieved in current long baseline neutrino experiments which use similar reconstruction techniques.
For example, the NOvA experiment quotes an absolute muon energy scale of $<1\%$ and a proton energy scale of 5\%~\cite{nova2018}.

\begin{table}
	\caption[$1\sigma$ uncertainties for the detector energy response used in the DUNE long baseline analysis]{$1\sigma$ uncertainties for the detector energy response used in the DUNE long baseline analysis. The muon curvature uncertainty only applies to those muons in the near detector which pass into the magnetised section of the detector. Conversely, the uncertainty on the energy scale of muons measured by range only applies for those muons which stop in ND-LAr.}
	\label{tab:energyScaleParams}
	\centering
	\begin{tabular}{c c c c}
		\hline
		\hline
		Particle types & \multicolumn{3}{c}{$1\sigma$ variation} \\
		& $p_{0}$ & $p_{1}$ & $p_{2}$ \\
		\hline
		All, except muons      & 2\%   & 1\%   & 2\%   \\
		$\mu$ (range)          & 2\%   & 2\%   & 2\%   \\
		$\mu$ (curvature)      & 1\%   & 1\%   & 1\%   \\
		$p$, \pipm             & 5\%   & 5\%   & 5\%   \\
		$e$, $\gamma$, \pizero & 2.5\% & 2.5\% & 2.5\% \\
		$n$                    & 20\%  & 30\%  & 30\% \\
		\hline
	\end{tabular}
\end{table}

$p_{1}$ and $p_{2}$ provide freedom in the shape of the energy response as a function of energy.
These coefficients are taken to be the same or similar to the size of $p_{0}$.

\citefig{fig:protonEScale} shows the $\pm1\sigma$ uncertainty on the energies of $p$ and \pipm as a function of energy.
This is produced by throwing the $p_{n}$ of \citeeq{eq:energyResponse} independently according to a Gaussian distribution with the appropriate width from \citetab{tab:energyScaleParams}. The function is then evaluated the centre of each energy bin.
This process is repeated \num{10000} times and a Gaussian is fitted to the distribution produced in each energy bin.
The value of $\sigma$ for each Gaussian is plotted as the size of the band.
One can see that there is significant variation in the uncertainty as a function of energy, caused by the different energy dependencies of the terms in \citeeq{eq:energyResponse}.
Additionally, central values of the distributions (black points) all lie close to 0.
In the actual fits, the full bin-to-bin correlations are kept and this plot is purely to illustrate the rough shape (in particle energy) of the energy scale uncertainties.

\begin{figure}[h]
  \begin{adjustbox}{max totalsize=.6\textwidth, center}
    \input{files/figures/dune_lbl/energyResponseBand}
  \end{adjustbox}
  \caption[Charged hadron energy scale uncertainty as a function of energy.]{Charged hadron energy scale uncertainty as a function of energy, generated from \num{10000} evaluations of \citeeq{eq:energyResponse} with Gaussian throws for $p_{0}$, $p_{1}$ and $p_{2}$. The red area indicates the $1\sigma$ fractional energy uncertainty while the black points indicate the central value for each energy bin. In the actual fits, the bin-to-bin correlations are kept.}
  \label{fig:protonEScale}
\end{figure}

Additionally, a 2\% uncertainty is assigned to the the resolution of muons, charged hadrons and electromagnetic objects while a 40\% uncertainty is applied to the resolution of neutrons.
These uncertainties can be expressed as energy shifts of the form
\begin{equation}
	E_{\alpha,~\text{reco}}' = E_{\alpha,~\text{reco}} + \left( E_{\alpha,~\text{true}} - E_{\alpha,~\text{reco}} \right) \times p_{\text{res}} \, ,
\end{equation}
where $E_{\alpha,~\text{true}}$ is the true energy of the particle in question and $p_{\text{res}}$ is allowed to vary in the fits.
The $1\sigma$ values for $p_{\text{res}}$ (the aforementioned 2\% and 40\%) are conservative estimates. 
The value for neutrons is much higher due to the large uncertainties in the amount of energy deposited by neutrons.

These uncertainties on particle energy scales are expected to derive from a variety of sources.
Some are inherent errors in the detector calibration such as a miscalculation of the electron lifetime, which will cause a bias in the energy scale of particles reconstructed using calorimetric methods.
Distortions in the electric field which are unaccounted for will also lead to these issues. 
They may also lead to errors in the reconstruction of track lengths, giving biased energy estimates for particles reconstructed from their range.

There are however, some detector systematics which are implemented as weights. 
Notably, a normalisation uncertainty of 1\% is applied to both \numu and \nue events.
This represents an estimate of the uncertainty on the fiducial volume of the FD.

Furthermore, systematic uncertainties for the near detector acceptance are devised based upon simulation of neutrino interactions in ND-LAr.
The acceptance of the DUNE ND is quite different to that of the FD due to the vastly different dimensions of the two detectors.
The muon acceptance of the DUNE near detector as a function of muon transverse and longitudinal momentum is shown in \citefigL{fig:ndAcceptance}. 
Muons are considered to be accepted if they either stop within ND-LAr or if they exit ND-LAr and pass into ND-GAr where their momentum may be measured from track curvature.
Those muons which exit ND-LAr without passing into ND-GAr are not accepted.

Neutrino events are rejected where they produce deposits of more than \SI{30}{\MeV} in the veto region of ND-LAr.
This veto region is defined as the outer \SI{30}{\cm} of the active region on all sides.
The resulting hadronic acceptance is shown in \citefigR{fig:ndAcceptance}.
One can see that the acceptance declines sharply as hadronic energy increases.

\begin{figure}[h]
	\begin{minipage}[t]{.5\textwidth}
		\begin{adjustbox}{max totalsize=\linewidth, center}
			\input{files/figures/dune_lbl/muonAcc}
		\end{adjustbox}
	\end{minipage}
	\hfill
	\begin{minipage}[t]{.5\textwidth}
		\begin{adjustbox}{max totalsize=\linewidth, center}
			\input{files/figures/dune_lbl/hadAcc}
		\end{adjustbox}
	\end{minipage}
	\caption[Muonic and hadronic acceptance for CC neutrino interactions in ND-LAr]{Left: Muonic acceptance for CC muon neutrino interactions in ND-LAr as a function of transverse and longitudinal muon momentum. Right: Hadronic acceptance for CC muon neutrino interactions in ND-LAr as a function of true hadronic energy. Both from~\cite{Abi:2020qib}.}
	\label{fig:ndAcceptance}
\end{figure}

The uncertainty on the muon and hadron acceptance is produced from the respective plots in \citefig{fig:ndAcceptance} with a higher uncertainty in regions where the acceptance is rapidly changing and thus vulnerable to mismodelling.

Unlike their FD counterparts, the ND detector parameters are not allowed to vary in the fit.
Instead, they are incorporated into a covariance matrix.
This covariance matrix is formed by throwing all ND detector uncertainties simultaneously according to their documented uncertainties and comparing the resulting spectra with the nominal prediction.
The bin-to-bin covariance is then determined using these comparisons.

This method differs from that used for the FD due to significant differences in the development of the ND and FD simulation.
The FD simulation uses a full detector simulation along with a fully simulated energy reconstruction based upon the Pandora toolkit~\cite{pandora}.
The ND simulation is much simpler. 
Although neutrino interactions are simulated within the ND volume in the same manner as the FD, with the interaction products being propagated through the detector using a Geant4-based model~\cite{geant}, sufficient reconstruction software has not yet been developed for ND-LAr.
Therefore a parametrised reconstruction is used, taking as inputs the true simulated energy deposits.
The high statistics of the ND, combined with this simplified detector model, leads to over-constraining of the ND detector parameters, if included as nuisance parameters.
The decision is therefore made to use the above method for the ND detector systematics.
This method is unnecessary in the FD where a full reconstruction is used.

\section{DUNE sensitivites}
\label{sec:dune_lbl:sensitivities}

\subsection{CAFAna}
\label{sec:dune_lbl:sensitivities:cafana}

DUNE's oscillation sensitivities are computed using the CAFAna package, further details of which are given here.
This framework derives its name from the input files which are known as Common Analysis Files (CAFs).
These files typically contain higher level reconstructed variables typically used by analysers and consist of a \texttt{ROOT}~\cite{root} \texttt{TTree}, each entry of which represents a suspected neutrino interaction~\cite{backhouse2015}.

CAFAna was originally developed for the NOvA oscillation analysis but has since been ported for use by both the DUNE and Short-Baseline Neutrino (SBN) collaborations~\cite{cafana}.
Its primary functions are the creation of histograms from the input files and the derivation of oscillation parameters from those histograms.

Additionally, CAFAna allows the effect of systematic variations on each output histogram to be viewed. 
These systematics can take the form of either reweightings or bin-to-bin shifting of events and are implemented as 1D response functions for each analysis bin.
The response functions for bin-to-bin shifts are constructed by taking the calculating the content of each bin at $\pm 1 \sigma$, $\pm 2 \sigma$ and $\pm 3 \sigma$ and then performing a cubic interpolation between these points.

In terms of CAFAna's fitting components, a frequentist approach is adopted with the minimisation being performed by the \texttt{MINUIT}~\cite{minuit} package.

The entire framework is written in C++ and may be controlled by the user through \texttt{ROOT} macros.

\subsection{General sensitivity methods}
\label{sec:dune_lbl:sensitivities:general}

Oscillation sensitivities are computed by simultaneously fitting the oscillation parameters and nuisance parameters to four FD spectra (\numu disappearance, \anumu disappearance, \nue appearance and \anue appearance) and the nuisance parameters to the two ND spectra (\numu unoscillated and \anumu unoscillated).
In the current DUNE analysis the intrinsic \nue beam flux is not constrained by the ND due to the simplicity of the ND reconstruction.
However, in a real analysis it is expected that this would be included.

Examples of the four FD event rates as a function of reconstructed neutrino energy are shown in \citefig{fig:fdEventRatesWithErrorBand}.
In each case, the $\pm1\sigma$ systematic error band is also shown in red.
Furthermore, for the appearance samples, the different event rates resulting from different neutrino mass hierarchies and values of \dcp are shown, while for the disappearance samples the effect of varying \thetai{23} is shown.
One can see that the systematic errors are significant for all samples across the energy range.
The variation in the appearance rates with \dcp is larger than the expected variation due to the systematics.
However, the systematic uncertainty is comparable to the expected \thetai{23} variation, indicating that tight constraints of these systematics will be required to make precision measurements of this variable.

\begin{figure}
	\begin{minipage}[t]{.5\linewidth}
		\begin{adjustbox}{max totalsize=\linewidth, center}
			\input{files/figures/dune_lbl/fdNumuFhcWithSyst}
		\end{adjustbox} \\
		\begin{adjustbox}{max totalsize=\linewidth, center}
			\input{files/figures/dune_lbl/fdNueFhcWithSyst}
		\end{adjustbox}
	\end{minipage}
	\hfill
	\begin{minipage}[t]{.5\linewidth}
		\begin{adjustbox}{max totalsize=\linewidth, center}
			\input{files/figures/dune_lbl/fdNumuRhcWithSyst}
		\end{adjustbox} \\
		\begin{adjustbox}{max totalsize=\linewidth, center}
			\input{files/figures/dune_lbl/fdNueRhcWithSyst}
		\end{adjustbox}
	\end{minipage}
	\caption[DUNE far detector event rates with systematic error bands.]{Event rates for each of the far detector samples. The red band indicates the $\pm1\sigma$ error systematic band for the normal hierarchy, $\dcp = \frac{\pi}{2}$ case. For the \nue event rates, results for different neutrino mass hierarchies and values of \dcp are shown. For the \numu event rates the effect of varying \thetai{23} is between the central value (\ang{49.6}) and a $3\sigma$ error (from Ref.~\cite{nufit4}) is shown. The \numu event rate does not depend on the hierarchy or the value of \dcp. The full MC statistics are used for these plots (with a scaling factor) with no fluctuations so the statistical uncertainty is not shown. Top left: \numu disappearance with the beam in FHC mode. Top right: \numu disappearance with the beam in RHC mode. Bottom left: \nue appearance with the beam in FHC mode. Bottom right: \nue appearance with the beam in RHC mode.}
	\label{fig:fdEventRatesWithErrorBand}
\end{figure}

The two ND samples are two dimensional, binned in reconstructed neutrino energy and reconstructed inelasticity, $y_{\text{reco}}$.
The reconstructed neutrino energy, $E_{\nu,~\text{reco}}$, is calculated by summing the reconstructed energy of the outgoing lepton ($E_{\mu,~\text{reco}}$) and the reconstructed energies of any final state hadrons ($E_{\text{had, reco}}$).
$y_{\text{reco}}$ is defined as
\begin{equation}
	y_{\text{reco}} = \frac{E_{\text{had, reco}}}{ E_{\text{had, reco}} + E_{\mu,~\text{reco}} } \, .
\end{equation}
These two-dimensional samples are shown in \citefig{fig:ndEventRates}.

\begin{figure}[h]
	\begin{minipage}[t]{.5\linewidth}
		\begin{adjustbox}{max totalsize=\linewidth, center}
			\input{files/figures/dune_lbl/h2NDNumuFHC}
		\end{adjustbox}
	\end{minipage}
	\hfill
	\begin{minipage}[t]{.5\linewidth}
		\begin{adjustbox}{max totalsize=\linewidth, center}
			\input{files/figures/dune_lbl/h2NDNumuRHC}
		\end{adjustbox}
	\end{minipage}
	\caption[Two-dimensional DUNE ND event rates used in the long-baseline analysis]{Two-dimensional DUNE ND event rates used in the long-baseline analysis. Left: Sample with the beam in neutrino mode. Right: Sample with the beam in antineutrino mode.}
	\label{fig:ndEventRates}
\end{figure}

One-dimensional projections of the samples shown in \citefig{fig:ndEventRates} are shown in \citefig{fig:ndEventRatesWithError} along with the $\pm1\sigma$ error band generated by the systematic uncertainties.
\begin{figure}
	\begin{minipage}[t]{.5\linewidth}
		\begin{adjustbox}{max totalsize=\linewidth, center}
			\input{files/figures/dune_lbl/ndFhcWithSyst}	
		\end{adjustbox}
	\end{minipage}
	\hfill
	\begin{minipage}[t]{.5\linewidth}
		\begin{adjustbox}{max totalsize=\linewidth, center}
			\input{files/figures/dune_lbl/ndRhcWithSyst}	
		\end{adjustbox}
	\end{minipage}
	\caption[One-dimensional DUNE ND event rates used in the long-baseline analysis with $\pm1\sigma$ systematic error band. The full MC statistics are used for these plots (with a scaling factor) with no fluctuations so the statistical uncertainty is not shown.]{One-dimensional DUNE ND event rates used in the long-baseline. The red band indicates the $\pm1\sigma$ systematic error band. Left: Event rate with the beam in FHC mode. Right: Event rate with the beam in RHC mode.}
	\label{fig:ndEventRatesWithError}
\end{figure}


In these fits Gaussian penalty terms on \thetai{12}, \deltami{21} and $\rho$ are applied (since DUNE will not be able to constrain these parameters).
The width and central values of these penalty terms are taken from the NuFit 4.0 global fit~\cite{nufit4}.
A penalty term on \thetai{13} may also be included.
However in the studies included in this chapter, it is not.
DUNE will eventually be able to constrain \thetai{13} with a similar precision to existing reactor experiments. 
However, this is expected to take around 15 years of running~\cite{tdrVol2}.
The other oscillation parameters, \ssthetai{23}, \deltami{32} and \dcp are allowed to vary freely.

In a typical oscillation analysis the compatibility of a particular set of oscillation parameters is evaluated using a negative log-likelihood ratio,
In the high statistics limit for Poisson-distributed data, this log-likelihood ratio converges to a $\chi^{2}$ and is given by~\cite{pdg2018}:
\begin{align}
	\chi^{2} &= -2 \log \mathcal{L} \\
	& = 2 \sum_{i}^{N_{\text{bins}}} \left[ M_{i} - D_{i} + D_{i} \ln \left( \frac{D_{i}}{M_{i}} \right) \right]
\end{align}
where $M_{i}$ and $D_{i}$ are the Monte Carlo expectation and observed count for the $i$th histogram bin respectively.

The $M_{i}$ for oscillated FD predictions are generated using simulated events where both the true and reconstructed properties of the neutrino interaction are known.
These are then used to fill 2D histograms (with the second axis being the true neutrino energy) for each oscillation channel ($\nu_{\alpha} \rightarrow \nu_{\beta}$).
These are then reweighted by the oscillation probability as a function of true energy, $P_{\alpha\beta}(E)$, to give the result
\begin{equation}
	M_{i} = \sum_{\alpha}^{e, \mu} \sum_{\beta}^{e, \mu, \tau} \sum_{j} P_{\alpha\beta}(E_{j}) M_{ij}^{\alpha\beta} \, .	
\end{equation}

The systematic parameters detailed in \citesec{sec:dune_lbl:systs} are included as nuisance parameters in the fit. 
These can have an arbitrary effect on the MC predictions and can affect different channels in different ways.
These parameters are profiled over in order to minimise the value of \chisquare and are prevented from moving too far from their expected values by gaussian penalty terms.
These penalty terms reflect our prior knowledge of what constitutes a likely variation in a given parameter.
To determine $M_{i}$ for a given set of systematic parameters, $M_{ij}^{\alpha\beta}$ is evaluated for each systematic parameter at $\pm1,2,3\sigma$ and an interpolation is used.

Including the systematic parameters and the covariance matrix gives $\chi^{2}$ for a given set of oscillation parameters, $\bm{\theta}$, and nuisance parameters, $\vb{x}$, as
\begin{align}
	\chi^{2} \left( \bm{\theta}, \vb{x} \right) &= -2 \log \mathcal{L} \left( \bm{\theta}, \vb{x} \right) \\
	&= 2 \sum_{i}^{N_{\text{bins}}} \left[ M_{i} (\bm{\theta}, \vb{x}) - D_{i} + D_{i} \ln \left( \frac{D_{i}}{M_{i}(\bm{\theta}, \vb{x})} \right) \right] + \sum_{j}^{N_{\text{systs}}} \left[ \frac{\Delta x_{j}}{\sigma_{j}} \right]^{2} \nonumber \\
	&+ \sum_{k}^{N^{\text{ND}}_{\text{bins}}} \sum_{l}^{ N_{\text{bins}}^{\text{ND}} } \left(  M_{k} (\vb{x}) - D_{k} \right) V_{kl}^{-1} \left( M_{l}(\vb{x}) - D_{l} \right) \, ,
\end{align}
where $M_{i}(\bm{\theta}, \vb{x})$ is the Monte Carlo expectation for a given set of $\bm{\theta}$ and $\vb{x}$ for the $i$th bin. 
$V_{kl}$ is the ND covariance matrix discussed in \citesec{sec:dune_lbl:systs:det}.
$\Delta x_{j}$ is the difference between the nominal and current value of the $j$th nuisance parameter and $\sigma_{j}$ is the prior uncertainty on said parameter.
The best fit values for the $\bm{\theta}$ and $\vb{x}$ occur at the minimum value of $\chi^{2}$.

The $D_{i}$ may or may not have Poisson fluctuations added depending on the type of study in question.
The fits utilised in this chapter are all Asimov studies~\cite{asimov}.
In these fits, the fake dataset is the same as the nominal Monte Carlo up to some scaling exposure and there are no throws of oscillation parameters, the systematic parameters or the bin statistics.
These fits provide the median sensitivity without the need to run many toy fits with statistical and systematic fluctuations.

In order to avoid reporting a false minimum $\chi^{2}$ as the true one, each fit is repeated at multiple sets of oscillation parameters. 
The values of \dcp tested are $-\pi$, $-\pi/2$, 0 and $\pi/2$. 
Additionally, both neutrino mass hierarchies are tested along with both octants of \thetai{23}.
From these, the fit which provides the lowest \chisquare is selected as the best fit point.

\subsection{Constraints on systematic parameters}

\citefig{fig:systConstraints} shows the systematics used in the DUNE long-baseline analysis.
For each parameter, the ratio of the post-fit to pre-fit uncertainties is shown for a 15 year staged exposure (\SI{1104}{\kilo\tonne\mega\watt\year}).
The constraints with just the FD are shown in red, while the green lines show the constraints with both the ND and FD samples.
The constraints are divided up depending on if they fall into the category of detector, flux or cross-section uncertainties.

\begin{figure}[h]
	\centering
	\includegraphics[width=.8\linewidth]{files/figures/dune_lbl/constraintsWithLines}
	\caption[DUNE systematic constraints with and without a near detector constraint]{Ratio of post-fit to pre-fit systematic constraints for a 15 year staged exposure. The constraints with (green) and without a ND constraint (red) are shown. The systematics are separated by category. Taken from~\cite{Abi:2020qib}.}
	\label{fig:systConstraints}
\end{figure}

For the detector systematics, one can see that the vast majority are not well constrained, either by the FD samples or with the additional ND samples.
Given that most of these parameters affect particles in the FD only it is reassuring to see that the addition of ND samples does not increase the constraints on most of these parameters.

The flux parameters are labelled as ``flux~$i$'', representing the $i\text{th}$ principal component of the matrix described in \citesec{sec:dune_lbl:systs:flux}.
One can see that most of the flux components are not constrained at all by the FD samples but with the inclusion of the ND, all become noticeably more constrained.

The level at which various cross-section parameters are constrained shows significant variation. 
For the most part (similar to the flux systematics), these parameters are not well constrained by the FD only, showing the utility of the ND.


\subsection{Mass hierarchy}
\label{sec:dune_lbl:sensitivities:mh}

DUNE's sensitivity to the neutrino mass hierarchy is measured using the statistic $\Delta \chisquare = \chi^{2}_{\text{B}} - \chi^{2}_{\text{A}}$, where $A$ and $B$ are two possible hypotheses.
This provides a measure of how well the data can exclude hypothesis $B$ in favour of $A$.
In the case of the neutrino mass hierarchy, the relevant question is to what level DUNE can exclude the inverted hierarchy in favour of the normal hierarchy (in the case of true normal hierarchy), $\chi^{2}_{\text{IH}} - \chi^{2}_{\text{NH}}$, and vice versa if the hierarchy is truly inverted.

This is repeated for various true values of \dcp, for both hierarchies in \citefig{fig:mhSens}.
For each \dcp point, $\Delta \chisquare$ is calculated by first calculating $\chi^{2}_{\text{true}}$ (where this can be either the normal or inverted hierarchy) and then calculating the \chisquare value for the same value of \dcp but with the hierarchy fixed to the incorrect value.
The square root of $\Delta \chisquare$ is then taken to provide a crude significance.

\begin{figure}[h]
	\begin{adjustbox}{max totalsize=.6\linewidth, center}
		\input{files/figures/dune_lbl/mh_sens_both}
	\end{adjustbox}
	\caption[DUNE sensitivity to the neutrino mass hierarchy as a function of true \dcp.]{DUNE sensitivities to the neutrino mass hierarchy as a function of true \dcp for a 7 year staged exposure. The black line shows the statistics-only case. The blue line shows the case where only the detector systematics are used. The red line shows the case where all systematics are used. Solid lines show the case for true normal mass hierarchy while dashed lines show the case for true inverted mass hierarchy. The two horizontal dashed lines are at $\sqrt{\Delta\chi^{2}} = 3, 5$ and represent important milestones in determining the mass hierarchy.}
	\label{fig:mhSens}
\end{figure}

\citefig{fig:mhSens} shows the results of this in the statistics-only case (for 7 years of staged running - equivalent to an exposure of \SI{336}{\kilo\tonne\mega\watt\year}), with just the detector systematics and also all the systematics included.
It is immediately apparent that DUNE will be highly sensitive to the neutrino mass hierarchy, surpassing the common particle physics threshold of $\sqrt{\Delta \chisquare} = 5$ at all values of \dcp and for both true hierarchies.
One can see that the addition of detector systematics reduces the sensitivity somewhat, with remaining systematics reducing it further.
However, it is clear that, even with a fairly substantial increase in systematic uncertainties, DUNE will still be able to quickly resolve the neutrino mass hierarchy.
This excellent ability to resolve the mass hierarchy stems from DUNE's long baseline which increases the size of matter effects on the oscillations. 
Since these matter effects are dependent on the true neutrino mass hierarchy, a longer baseline allows a quicker determination of the true mass hierarchy.

\citefig{fig:mhSensExp} illustrates just how quickly DUNE will be able to resolve the mass hierarchy.
\citefig{fig:mhSensExp} shows the value of $\sqrt{\Delta\chisquare}$ in the case of true normal neutrino mass hierarchy and $\dcpTrue = \pi/2$ as a function of far detector exposure. 
Looking at \citefig{fig:mhSens}, one can see that this is the value at which DUNE is least sensitive to the mass hierarchy and thus a worst-case scenario for DUNE to make this measurement.
Therefore, regardless of the choice of \dcp, one can see that DUNE would pass the $\sqrt{\Delta\chisquare}=3$ threshold after an exposure of roughly \SI{22}{\kilo\tonne\mega\watt\year}.
Similarly, the $\sqrt{\Delta\chisquare}=5$ threshold is passed after an exposure of roughly \SI{78}{\kilo\tonne\mega\watt\year}.
Given that the full DUNE FD is expected to have a fiducial mass of \SI{40}{\kilo\tonne} and an initial beam power of \SI{1.2}{\mega\watt}, the required exposure for definitive discovery of the mass hierachy could be accumulated in less than 2 years.

\begin{figure}[h]
	\begin{adjustbox}{max totalsize=.6\linewidth, center}
		\input{files/figures/dune_lbl/mh_sens_exp_nh}
	\end{adjustbox}
	\caption[DUNE's sensitivity to the neutrino mass hierarchy as a function of exposure]{DUNE's sensitivity to the neutrino mass hierarchy as a function of exposure in the case of true normal hierarchy and $\dcp=\pi/2$.}
	\label{fig:mhSensExp}
\end{figure}

One can also see that the addition of the systematics does little here to reduce DUNE's sensitivity to the mass ordering.

\subsection{Charge-parity symmetry violation}
\label{sec:dune_lbl:sensitivities:cpv}

In a similar manner to the mass hierarchy, DUNE's sensitivity to CP-violation in the lepton sector is calculated using the likelihood ratio, $\Delta \chisquare$.
In this case DUNE is attempting to exclude the models where $\dcp = 0$ or $\pi$ (CP-conserving values of \dcp).
Therefore, $\Delta \chisquare = \chi^{2}_{\dcp=0,\pi} - \chi^{2}_{\text{CPV}}$, where $\chi^{2}_{\text{CPV}}$ is the \chisquare value at the \dcp point tested and $\chisquare_{\dcp=0,\pi} = \min(\chisquare_{\dcp=0},~\chisquare_{\dcp=\pi})$.
$\chisquare_{\dcp=0}$ is evaluated by taking as the Monte Carlo expectation the same oscillation and nuisance parameters as the data but with \dcp fixed at 0.
A similar procedure is used to evaluate $\chisquare_{\dcp=\pi}$.
One can see that this distribution will necessarily be constrained to fall to $\Delta \chisquare = 0$ at CP conserving values of \dcp.

\citefig{fig:cpvSens} shows the resulting CPV sensitivity as a function of true \dcp.
Here, once again, the square root of $\Delta\chisquare$ has been taken in order to calculate a significance.
\citefigL{fig:cpvSens}, shows the CPV sensitivity in the case of a true normal neutrino mass hierarchy while \citefigR{fig:cpvSens} shows the same distribution in the case of a true inverted mass hierarchy.
The double-humped structure visible in both \citefig{fig:cpvSens} left and right, is a result of the aforementioned constraint on $\Delta\chisquare$ at CP conserving values.

\begin{figure}[h]
	\begin{minipage}[t]{.5\linewidth}
		\begin{adjustbox}{max totalsize=\linewidth, center}
			\input{files/figures/dune_lbl/cpv_sens_nh}
		\end{adjustbox}
	\end{minipage}
	\hfill
	\begin{minipage}[t]{.5\linewidth}
		\begin{adjustbox}{max totalsize=\linewidth, center}
			\input{files/figures/dune_lbl/cpv_sens_ih}
		\end{adjustbox}
	\end{minipage}
	\caption[DUNE sensitivities to CP-violation in the lepton sector as a function of true \dcp.]{DUNE sensitivities to CP-violation in the lepton sector as a function of true \dcp for 7 years of staged running. The black line shows the statistics-only case. The blue line shows the case where only the detector systematics are used. The red line shows the case where all systematics are used. Left: True normal neutrino mass hierarchy. Right: True inverted mass hierarchy.}
	\label{fig:cpvSens}
\end{figure}

Looking at \citefig{fig:cpvSens}, one can see that DUNE's sensitivity is slightly better in the case that the true neutrino mass hierarchy is inverted rather than normal.
In the case of the inverted hierarchy, after 7 years of running DUNE will have the potential to discover CPV if the true value of \dcp is near $-\pi/2$ or $\pi/2$ even with all systematics.
However, if the mass hierarchy is normal then DUNE's CPV discovery potential is lower. 
Under this 7 year running plan, DUNE will not reach the crucial $5\sigma$ discovery level when systematics are included. 
However, DUNE will still exceed the $3\sigma$ threshold for many values of \dcp with the full suite of systematics.

One interesting point that is observable in \citefig{fig:cpvSens} is that that most of the decrease in sensitivity from the statistics-only case occurs when only including the detector systematics.
Although there is a decrease from the blue to the red line upon the inclusion of the flux and cross-section systematics, it is much less substantial than the drop in sensitivity upon the inclusion of just the detector systematics.
It can therefore be assumed that in order for DUNE to reach its full potential, it will be very important to control the detector systematics.
