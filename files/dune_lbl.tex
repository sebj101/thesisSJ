\chapter{DUNE long-baseline analysis}
\label{sec:dune_lbl}

%%% Overall point of this chapter: How do our uncertainties relate to our ability to measure CPV
As covered in \citechap{sec:dune}, DUNE's primary goal is to make a measurement of CP violation (CPV) in the lepton sector.
Secondary to this are other goals such as the determination of the neutrino mass hierarchy and the precision measurement of some of the other parameters governing neutrino oscillations.

Prior to any construction of the experiment, it is important to assess DUNE's eventual sensitivity to both CPV and other oscillation physics.
In order to do this, sensitivity studies must be undertaken using simulated Monte Carlo fake data, which attempts to represent the data that DUNE is likely to gather during its operational phase.

In order to properly assess these sensitivities, a set of systematic uncertainties is evaluated, covering all parts of the DUNE experiment.
This chapter provides a brief description of these systematic uncertainties and their origins in \citesec{sec:dune_lbl:systs}.

Following on from this, \citesec{sec:dune_lbl:sensitivities} provides a description of the methods used to extract DUNE's sensitivities.
Also in this section, results are presented showing DUNE's sensitivity to both CPV in the lepton sector and the neutrino mass hierarchy.

\section{Summary of DUNE systematic uncertainties}
\label{sec:dune_lbl:systs}

This section gives a summary of the systematic uncertainties used in DUNE's long baseline analysis and where they are derived from.
\citesec{sec:dune_lbl:systs:flux} details the systematics deriving from lack of knowledge about the neutrino beam (commonly referred to as the `flux' systematics).
\citesec{sec:dune_lbl:systs:xsec} gives details of those systematics relating to lack of knowledge surrounding neutrino interactions with matter.
Finally, \citesec{sec:dune_lbl:systs:det} outlines the systematic uncertainties which derive from the uncertainty surrounding detector effects, for example the reconstructed energies of charged particles in the detector.

\subsection{Flux}
\label{sec:dune_lbl:systs:flux}

Uncertainties in the neutrino beam flux primarily arise from two sources: uncertainties in the production of hadrons by protons striking the beam target and uncertainties in the design parameters of the beam such as the horn currents or positioning (commonly referred to as the `focussing uncertainties').

The focussing uncertainties are evaluated by varying the beam line parameters within their tolerances and observing the resulting changes in the neutrino fluxes.
Hadron production uncertainties are estimated using uncertainties from thin target data experiments such as NA49~\cite{na49} with large uncertainties assigned to those interactions that are not covered by data.

\citefig{fig:fluxUncertainties} shows these uncertainties as a function of neutrino energy for the \numu and \anumu fluxes in both neutrino and antineutrino mode.
One can see that, at nearly all energies, hadron production uncertainties are larger than focussing uncertainties.

\begin{figure}[h]
  \centering
  \includegraphics[width=.8\linewidth]{files/figures/dune_detector/fluxUncertainties}
  \caption[Far detector flux uncertainties for \numu and \anumu]{Far detector \numu and \anumu flux uncertainties as a function of neutrino energy, from~\cite{tdrVol2}. The uncertainties are separated into those resulting from hadron production and those resulting from the focussing uncertainties.}
  \label{fig:fluxUncertainties}
\end{figure}

The flux uncertainties are evaluated by running many simulations of with variations of the hadron production and focussing uncertainties mentioned above and then using this information to build a covariance matrix.
This matrix is binned in neutrino energy and flavour.
The matrix is then diagonalised to give the various principal components, along with their eigenvalues.
The largest 30 of these principal components (when ordered by the size of their eigenvalues) are used as the flux systematic uncertainties.
Further details are available in Ref.~\cite{duneFluxUncertainties}.

These flux uncertainties can be compared with those from the T2K experiment, shown in \citefig{fig:t2kFluxUnc}.
The total flux uncertainties in the peak region of the unoscillated flux (a true neutrino energy of about \SI{0.6}{\GeV}) are about 15\%, slightly larger than those expected for DUNE.
NOvA reports flux uncertainties of 21\% in the peak region of the neutrino flux~\cite{novaFluxUnc}, again larger than those expected by DUNE.

\begin{figure}[h]
  \centering
  \includegraphics[width=.9\linewidth]{files/figures/dune_lbl/t2kFluxUncertainties}
  \caption[Fractional errors on beam neutrino fluxes in Super-Kamiokande]{Fractional errors on the beam neutrino fluxes in the Super-Kamiokande detector as a function of true neutrino energy, from~\cite{t2kFluxUnc}. The unoscillated neutrino flux peaks at \SI{0.6}{\GeV}. Left: Muon neutrinos. Right: Electron neutrinos.}
  \label{fig:t2kFluxUnc}
\end{figure}


\subsection{Neutrino interaction (cross-section)}
\label{sec:dune_lbl:systs:xsec}

%Uncertainties in the neutrino interaction model come from a variety of sources. 
The primary model used in the DUNE long-baseline analysis is that provided by the chosen neutrino interaction generator, Generates Events for Neutrino Interaction Experiments (GENIE)~\cite{genie}.
The version of GENIE used in the DUNE long-baseline analysis is v2.12.0~\cite{tdrVol2}.

The interaction model takes a neutrino flux and outputs the final state particles produced by said neutrinos interacting with the target medium.
For the most part, these interactions are modelled as factorising the interaction into three parts: an initial nuclear state, the neutrino interaction with a nucleon and the propagation of final state particles through the nucleus.

%% Might need to move section on neutrino nucleus interactions to here
The systematic uncertainties used in this analysis relate to all three elements of this modelling picture, among other categories.
The interaction model systematics can be divided into categories covering each of the following areas~\cite{tdrVol2}: 
\begin{itemize}
	\item Initial nuclear state
	\item Quasielastic processes
	\item Multinucleon (2p2h) processes
	\item Pion production processes
	\item High $W$ processes and neutral current processes
	\item Final state interactions
	\item Neutrino flavour dependent uncertainties
\end{itemize}

Many of the systematic uncertainties are included as standard in GENIE, while others are developed specifically for the DUNE long-baseline analysis.
These uncertainties take the form of either continuous weights or discrete model comparisons.
These uncertainties are derived from a variety of sources, including freedoms in theoretical models, current experimental measurements and observed discrepancies between models and experiments.

\subsection{Detector}
\label{sec:dune_lbl:systs:det}

Detector systematics in the DUNE long-baseline analysis primarily take the form of bin-to-bin energy shifts, rather than the weights typically used for the flux and cross-section systematics.
These are expressed as multi-parameter energy scale shifts for various final states particles species and are of the form
\begin{equation}
E_{\alpha,~\text{reco}}' = E_{\alpha,~\text{reco}} \left( p_{0} + p_{1} \sqrt{E_{\alpha,~\text{reco}}} + \frac{p_{2}}{\sqrt{E_{\alpha,~\text{reco}}+0.1}} \right) \, ,
\label{eq:energyResponse}	
\end{equation}
where the $p_{n}$ are allowed to vary in any fits.
\citetab{tab:energyScaleParams} shows the $1\sigma$ values of the $p_{n}$ for each of the particle types.
All of these uncertainties are treated as uncorrelated between the near and far detectors.
This decision is made due to the differences in detector technologies and likely calibration strategies between near and far detectors.

The values of the $p_{0}$ (the absolute scale factors) are motivated by those values achieved in current long baseline neutrino experiments which use similar reconstruction techniques.
For example, the NOvA experiment quotes an absolute muon energy scale of $<1\%$ and a proton energy scale of 5\%~\cite{nova2018}.

\begin{table}
	\caption[$1\sigma$ uncertainties for the detector energy response used in the DUNE long baseline analysis]{$1\sigma$ uncertainties for the detector energy response used in the DUNE long baseline analysis. The muon curvature uncertainty only applies to those muons in the near detector which pass into the magnetised section of the detector. Conversely, the uncertainty on the energy scale of muons measured by range only applies for those muons which stop in ND-LAr.}
	\label{tab:energyScaleParams}
	\centering
	\begin{tabular}{c c c c}
		\hline
		\hline
		Particle types & \multicolumn{3}{c}{$1\sigma$ variation} \\
		& $p_{0}$ & $p_{1}$ & $p_{2}$ \\
		\hline
		All, except muons      & 2\%   & 1\%   & 2\%   \\
		$\mu$ (range)          & 2\%   & 2\%   & 2\%   \\
		$\mu$ (curvature)      & 1\%   & 1\%   & 1\%   \\
		$p$, \pipm             & 5\%   & 5\%   & 5\%   \\
		$e$, $\gamma$, \pizero & 2.5\% & 2.5\% & 2.5\% \\
		$n$                    & 20\%  & 30\%  & 30\% \\
		\hline
	\end{tabular}
\end{table}

$p_{1}$ and $p_{2}$ provide freedom in the shape of the energy response as a function of energy.
These coefficients are taken to be the same or similar to the size of $p_{0}$.

\citefig{fig:protonEScale} shows the $\pm1\sigma$ uncertainty on the energies of $p$ and \pipm as a function of energy.
This is produced by throwing the $p_{n}$ independently according to a Gaussian distribution with the appropriate width from \citetab{tab:energyScaleParams}. The function is then evaluated the centre of each energy bin.
This process is repeated \num{10000} times and a Gaussian is fitted to the distribution produced in each energy bin.
The value of $\sigma$ for each Gaussian is plotted as the size of the band.
One can see that there is significant variation in the uncertainty as a function of energy, caused by the different energy dependencies of the terms in \citeeq{eq:energyResponse}.
Additionally, central values of the distributions (black points) all lie close to 0.

\begin{figure}[h]
  \begin{adjustbox}{max totalsize=.6\textwidth, center}
    \input{files/figures/dune_lbl/energyResponseBand}
  \end{adjustbox}
  \caption[Charged hadron energy scale uncertainty as a function of energy.]{Charged hadron energy scale uncertainty as a function of energy, generated from \num{10000} evaluations of \citeeq{eq:energyResponse} with Gaussian throws for $p_{0}$, $p_{1}$ and $p_{2}$. The red area indicates the $1\sigma$ fractional energy uncertainty while the black points indicate the central value for each energy bin.}
  \label{fig:protonEScale}
\end{figure}

Additionally, a 2\% uncertainty is assigned to the the resolution of each of muons, charged hadrons, electromagnetic objects while a 40\% uncertainty is applied to the resolution of neutrons.

These uncertainties on particle energy scales are expected to derive from a variety of sources.
Some are inherent errors in the detector calibration such as a miscalculation of the electron lifetime, which will cause a bias in the energy scale of particles reconstructed using calorimetric methods.
Distortions in the electric field which are unaccounted for will also lead to these issues. 
They may also lead to errors in the reconstruction of track lengths, giving biased energy estimates for particles reconstructed from their range.

There are however, some detector systematics which are implemented as weights. 
Notably, a normalisation uncertainty of 1\% is applied to both \numu and \nue events.

Furthermore, systematic uncertainties for the near detector acceptance are devised based upon simulation of neutrino interactions in ND-LAr.
The acceptance of the DUNE ND is quite different to that of the FD due to the vastly different dimensions of the two detectors.
The muon acceptance of the DUNE near detector as a function of muon transverse and longitudinal momentum is shown in \citefigL{fig:ndAcceptance}. 
Muons are considered to be accepted if they either stop within ND-LAr or if they exit ND-LAr and pass into ND-GAr where their momentum may be measured from track curvature.
Those muons which exit ND-LAr without passing into ND-GAr are not accepted.

Neutrino events are rejected where they produce deposits of more than \SI{30}{\MeV} in the veto region of ND-LAr.
This veto region is defined as the outer \SI{30}{\cm} of the active region on all sides.
The resulting hadronic acceptance is shown in \citefigR{fig:ndAcceptance}.
One can see that the acceptance declines sharply as hadronic energy increases.

\begin{figure}[h]
	\begin{minipage}[t]{.5\textwidth}
		\begin{adjustbox}{max totalsize=\linewidth, center}
			\input{files/figures/dune_lbl/muonAcc}
		\end{adjustbox}
	\end{minipage}
	\hfill
	\begin{minipage}[t]{.5\textwidth}
		\begin{adjustbox}{max totalsize=\linewidth, center}
			\input{files/figures/dune_lbl/hadAcc}
		\end{adjustbox}
	\end{minipage}
	\caption[Muonic and hadronic acceptance for CC neutrino interactions in ND-LAr]{Left: Muonic acceptance for CC muon neutrino interactions in ND-LAr as a function of transverse and longitudinal muon momentum. Right: Hadronic acceptance for CC muon neutrino interactions in ND-LAr as a function of true hadronic energy. Both from~\cite{Abi:2020qib}.}
	\label{fig:ndAcceptance}
\end{figure}

The uncertainty on the muon and hadron acceptance is produced from the respective plots in \citefig{fig:ndAcceptance} with a higher uncertainty in regions where the acceptance is rapidly changing and thus vulnerable to mismodelling.

Unlike their FD counterparts, the ND detector parameters are not allowed to vary in the fit.
Instead, they are incorporated into a covariance matrix.
This covariance matrix is formed by throwing all ND detector uncertainties simultaneously according to their documented uncertainties and comparing the resulting spectra with the nominal prediction.
The bin-to-bin covariance is then determined using these comparisons.
This method protects against over-constraining of ND parameters due to the limitations of the simplified ND reconstruction.

\section{DUNE sensitivites}
\label{sec:dune_lbl:sensitivities}

\subsection{CAFAna}
\label{sec:dune_lbl:sensitivities:cafana}

DUNE's oscillation sensitivities are computed using the CAFAna package, further details of which are given here.
This framework derives its name from the input files which are known as Common Analysis Files (CAFs).
These files typically contain higher level reconstructed variables typically used by analysers and consist of a \texttt{ROOT}~\cite{root} \texttt{TTree}, each entry of which represents a suspected neutrino interaction~\cite{backhouse2015}.

CAFAna was originally developed for the NOvA oscillation analysis but has since been ported for use by both the DUNE and Short-Baseline Neutrino (SBN) collaborations~\cite{cafana}.
Its primary functions are the creation of histograms from the input files and the derivation of oscillation parameters from those histograms.

Histograms can be easily plotted by specifying a dataset, variable (\texttt{Var}), selection (\texttt{Cut}) and binning (both constant and variable are supported). 
\texttt{Var}s may be simply the quantities contained within the CAF \texttt{TTree} or may be constructed from combinations of these.
Similarly, \texttt{Cut}s may be user defined and can be easily combined using the C++ logical operators.

Additionally, CAFAna allows the effect of systematic variations on each output histogram to be viewed. 
These systematics can take the form of either reweightings or bin-to-bin shifting of events and are implemented as 1D response functions for each analysis bin.
The response functions for bin-to-bin shifts are constructed by taking the calculating the content of each bin at $\pm 1 \sigma$, $\pm 2 \sigma$ and $\pm 3 \sigma$ and then performing a cubic interpolation between these points.

In terms of CAFAna's fitting components, a frequentist approach is adopted with the minimisation being performed by the \texttt{MINUIT}~\cite{minuit} package.
However, currently work is ongoing to expand CAFAna to allow Bayesian analyses.

The entire framework is written in C++ and may be controlled by the user through \texttt{ROOT} macros.

\subsection{General sensitivity methods}
\label{sec:dune_lbl:sensitivities:general}

Oscillation sensitivities are computed by simultaneously fitting the oscillation parameters and nuisance parameters to four FD spectra (\numu disappearance, \anumu disappearance, \nue appearance and \anue appearance) and the nuisance parameters to the two ND spectra (\numu unoscillated and \anumu unoscillated).
In the current DUNE analysis the intrinsic \nue beam flux is not constrained by the ND due to the simplicity of the ND reconstruction.
However, in a real analysis it is expected that this would be included.

Examples of the four FD event rates are shown in \citefig{fig:fdEventRatesWithErrorBand}.
In each case, the $\pm1\sigma$ systematic error band is also shown in red.
Furthermore, for the appearance samples, the different event rates resulting from different neutrino mass hierarchies and values of \dcp are shown.
One can see that the systematic errors are significant for all samples across the energy range.

\begin{figure}
	\begin{minipage}[t]{.5\linewidth}
		\begin{adjustbox}{max totalsize=\linewidth, center}
			\input{files/figures/dune_lbl/fdNumuFhcWithSyst}
		\end{adjustbox} \\
		\begin{adjustbox}{max totalsize=\linewidth, center}
			\input{files/figures/dune_lbl/fdNueFhcWithSyst}
		\end{adjustbox}
	\end{minipage}
	\hfill
	\begin{minipage}[t]{.5\linewidth}
		\begin{adjustbox}{max totalsize=\linewidth, center}
			\input{files/figures/dune_lbl/fdNumuRhcWithSyst}
		\end{adjustbox} \\
		\begin{adjustbox}{max totalsize=\linewidth, center}
			\input{files/figures/dune_lbl/fdNueRhcWithSyst}
		\end{adjustbox}
	\end{minipage}
	\caption[DUNE far detector event rates with systematic error bands.]{Event rates for each of the far detector samples. The red band indicates the $\pm1\sigma$ error systematic band for the normal hierarchy, $\dcp = \frac{\pi}{2}$ case. For the \nue event rates, results for different neutrino mass hierarchies and values of \dcp are shown. For the \numu event rates the effect of varying \thetai{23} is shown. The \numu event rate does not depend on the hierarchy or the value of \dcp. Top left: \numu disappearance with the beam in FHC mode. Top right: \numu disappearance with the beam in RHC mode. Bottom left: \nue appearance with the beam in FHC mode. Bottom right: \nue appearance with the beam in RHC mode.}
	\label{fig:fdEventRatesWithErrorBand}
\end{figure}

The two ND samples are two dimensional, binned in reconstructed neutrino energy and reconstructed inelasticity, $y_{\text{reco}}$.
The reconstructed neutrino energy, $E_{\nu,~\text{reco}}$, is calculated by summing the reconstructed energy of the outgoing lepton ($E_{\mu,~\text{reco}}$) and the reconstructed energies of any final state hadrons ($E_{\text{had, reco}}$).
$y_{\text{reco}}$ is defined as
\begin{equation}
	y_{\text{reco}} = \frac{E_{\text{had, reco}}}{ E_{\text{had, reco}} + E_{\mu,~\text{reco}} } \, .
\end{equation}
These two-dimensional samples are shown in \citefig{fig:ndEventRates}.

\begin{figure}[h]
	\begin{minipage}[t]{.5\linewidth}
		\begin{adjustbox}{max totalsize=\linewidth, center}
			\input{files/figures/dune_lbl/h2NDNumuFHC}
		\end{adjustbox}
	\end{minipage}
	\hfill
	\begin{minipage}[t]{.5\linewidth}
		\begin{adjustbox}{max totalsize=\linewidth, center}
			\input{files/figures/dune_lbl/h2NDNumuRHC}
		\end{adjustbox}
	\end{minipage}
	\caption[Two-dimensional DUNE ND event rates used in the long-baseline analysis]{Two-dimensional DUNE ND event rates used in the long-baseline analysis. Left: Sample with the beam in neutrino mode. Right: Sample with the beam in antineutrino mode.}
	\label{fig:ndEventRates}
\end{figure}

One-dimensional projections of the samples shown in \citefig{fig:ndEventRates} are shown in \citefig{fig:ndEventRatesWithError} along with the $\pm1\sigma$ error band generated by the systematic uncertainties.
\begin{figure}
	\begin{minipage}[t]{.5\linewidth}
		\begin{adjustbox}{max totalsize=\linewidth, center}
			\input{files/figures/dune_lbl/ndFhcWithSyst}	
		\end{adjustbox}
	\end{minipage}
	\hfill
	\begin{minipage}[t]{.5\linewidth}
		\begin{adjustbox}{max totalsize=\linewidth, center}
			\input{files/figures/dune_lbl/ndRhcWithSyst}	
		\end{adjustbox}
	\end{minipage}
	\caption[One-dimensional DUNE ND event rates used in the long-baseline analysis with $\pm1\sigma$ systematic error band.]{One-dimensional DUNE ND event rates used in the long-baseline. The red band indicates the $\pm1\sigma$ systematic error band. Left: Event rate with the beam in FHC mode. Right: Event rate with the beam in RHC mode.}
	\label{fig:ndEventRatesWithError}
\end{figure}


In these fits Gaussian penalty terms on \thetai{12}, \deltami{21} and $\rho$ are applied (since DUNE will not be able to constrain these parameters).
The width and central values of these penalty terms are taken from the NuFit 4.0 global fit~\cite{nufit4}.
A penalty term on \thetai{13} may also be included.
However in the studies included in this chapter, it is not.
DUNE will eventually be able to constrain \thetai{13} with a similar precision to existing reactor experiments. 
However, this is expected to take around 15 years of running~\cite{tdrVol2}.
The other oscillation parameters, \ssthetai{23}, \deltami{32} and \dcp are allowed to vary freely.

The compatibility of a particular set of near and far detector data with a given set of oscillation parameters and nuisance parameter values is evaluated using a negative log-likelihood ratio.
In the high statistics limit, this log-likelihood ratio converges to a $\chi^{2}$~\cite{pdg2018}.
The expression for this $\chi^{2}$ for a given set of oscillation parameters, $\bm{\theta}$, and nuisance parameters, $\vb{x}$ is given by
\begin{align}
	\chi^{2} \left( \bm{\theta}, \vb{x} \right) &= -2 \log \mathcal{L} \left( \bm{\theta}, \vb{x} \right) \\
	&= 2 \sum_{i}^{N_{\text{bins}}} \left[ M_{i} (\bm{\theta}, \vb{x}) - D_{i} + D_{i} \ln \left( \frac{D_{i}}{M_{i}(\bm{\theta}, \vb{x})} \right) \right] + \sum_{j}^{N_{\text{systs}}} \left[ \frac{\Delta x_{j}}{\sigma_{j}} \right]^{2} \\
	&+ \sum_{k}^{N^{\text{ND}}_{\text{bins}}} \sum_{l}^{ N_{\text{bins}}^{\text{ND}} } \left(  M_{k} (\vb{x}) - D_{k} \right) V_{kl}^{-1} \left( M_{l}(\vb{x}) - D_{l} \right) \, ,
\end{align}
where $D_{i}$ and $M_{i}(\bm{\theta}, \vb{x})$ are the fake data and Monte Carlo expectation for a given set of $\bm{\theta}$ and $\vb{x}$ for the $i$th bin respectively. 
$V_{kl}$ is the ND covariance matrix mentioned in \citesec{sec:dune_lbl:systs:det}.
$\Delta x_{j}$ is the difference between the nominal and current value of the $j$th nuisance parameter and $\sigma_{j}$ is the prior uncertainty on said parameter.
The best fit values for the $\bm{\theta}$ and $\vb{x}$ occur at the minimum value of $\chi^{2}$.

In order to avoid reporting a false minimum $\chi^{2}$ as the true one, each fit is repeated at multiple sets of oscillation parameters. 
The values of \dcp tested are $-\pi$, $-\pi/2$, 0 and $\pi/2$. 
Additionally, both neutrino mass hierarchies are tested along with both octants of \thetai{23}.
From these, the fit which provides the lowest \chisquare is selected as the best fit point.

%% Something about Asimovs
The fits utilised in this chapter are all Asimov studies~\cite{asimov}.
In these fits, the fake dataset is the same as the nominal Monte Carlo up to some scaling exposure and there are no throws of oscillation parameters, the systematic parameters or the bin statistics.

\subsection{Constraints on systematic parameters}

\citefig{fig:systConstraints} shows the systematics used in the DUNE long-baseline analysis.
For each parameter, the ratio of the post-fit to pre-fit uncertainties is shown.
The constraints with just the FD are shown in red, while the green lines show the combined near and far detector constraints.
One can see that, as expected, the FD detector parameters are not significantly more constrained with the addition of the ND samples. 

\begin{figure}[h]
	\centering
	\includegraphics[width=.8\linewidth]{files/figures/dune_lbl/constraintsWithLines}
	\caption[DUNE systematic constraints with and without a near detector constraint]{Ratio of post-fit to pre-fit systematic constraints for a 15 year staged exposure. The constraints with (green) and without a ND constraint (red) are shown. The systematics are separated by category. Taken from~\cite{Abi:2020qib}.}
	\label{fig:systConstraints}
\end{figure}

There is also significant variation in the level at which various cross-section parameters are constrained. 
For the most part, these parameters are not well constrained by the FD only, showing the utility of the ND.
Similarly, the flux parameters become significantly more constrained with the addition of the ND.

\subsection{Mass hierarchy}
\label{sec:dune_lbl:sensitivities:mh}

DUNE's sensitivity to the neutrino mass hierarchy is measured using the statistic $\Delta \chisquare = \chi^{2}_{\text{B}} - \chi^{2}_{\text{A}}$, where $A$ and $B$ are two possible hypotheses.
This provides a measure of how well the data can exclude hypothesis $B$ in favour of $A$.
In the case of the neutrino mass hierarchy, the relevant question is to what level DUNE can exclude the inverted hierarchy in favour of the normal hierarchy (in the case of true normal hierarchy), $\chi^{2}_{\text{IH}} - \chi^{2}_{\text{NH}}$, and vice versa if the hierarchy is truly inverted.

This is verified for various true values of \dcp, for both hierarchies in \citefig{fig:mhSens}.
For each \dcp point $\Delta \chisquare$ is calculated by first calculating $\chi^{2}_{\text{true}}$ (where this can be either the normal or inverted hierarchy) and then calculating the \chisquare value for the same value of \dcp but with the hierarchy fixed to the incorrect value.
The square root of $\Delta \chisquare$ is then taken to provide a crude significance.

\begin{figure}[h]
	\begin{adjustbox}{max totalsize=.6\linewidth, center}
		\input{files/figures/dune_lbl/mh_sens_both}
	\end{adjustbox}
	\caption[DUNE sensitivity to the neutrino mass hierarchy as a function of true \dcp.]{DUNE sensitivities to the neutrino mass hierarchy as a function of true \dcp for a 7 year staged exposure. The black line shows the statistics only case. The blue line shows the case where only the detector systematics are used. The red line shows the case where all systematics are used. Solid lines show the case for true normal mass hierarchy while dashed lines show the case for true inverted mass hierarchy. The two horizontal dashed lines are at $\sqrt{\Delta\chi^{2}} = 3, 5$ and represent important milestones in determining the mass hierarchy.}
	\label{fig:mhSens}
\end{figure}

\citefig{fig:mhSens} shows the results of this in the statistics only case (for 7 years of staged running - equivalent to an exposure of \SI{336}{\kilo\tonne\mega\watt\year}), with just the detector systematics and with all the systematics included.
It is immediately apparent that DUNE will be highly sensitive to the neutrino mass hierarchy, surpassing the common particle physics threshold of $\sqrt{\Delta \chisquare} = 5$ at all values of \dcp and for both true hierarchies.
One can see that the addition of detector systematics reduces the sensitivity somewhat, with remaining systematics reducing it further.
However, it is clear that, even with a fairly substantial increase in systematic uncertainties, DUNE will still be able to quickly resolve the neutrino mass hierarchy.
This excellent ability to resolve the mass hierarchy stems from the DUNE's long baseline which increases the size of matter effects on the oscillations. 
Since these matter effects are dependent on the true neutrino mass hierarchy, a longer baseline provides a more effective determinant of the true mass hierarchy.

\citefig{fig:mhSensExp} illustrates just how quickly DUNE will be able to resolve the mass hierarchy.
\citefig{fig:mhSensExp} shows the value of $\sqrt{\Delta\chisquare}$ in the case of true normal neutrino mass hierarchy and $\dcpTrue = \pi/2$ as a function of far detector exposure. 
Looking at \citefig{fig:mhSens}, one can see that this is the point at which DUNE is least sensitive and thus a worst-case scenario for DUNE to make this measurement.
Regardless of the choice of \dcp therefore, one can see that DUNE would pass the $\sqrt{\Delta\chisquare}=3$ threshold after an exposure of roughly \SI{22}{\kilo\tonne\mega\watt\year}.
Similarly, the $\sqrt{\Delta\chisquare}=5$ threshold is passed after an exposure of roughly \SI{78}{\kilo\tonne\mega\watt\year}.
Given that the full DUNE FD is expected to have a fiducial mass of \SI{40}{\kilo\tonne} and an initial beam power of \SI{1.2}{\mega\watt}, the required exposure for definitive discovery of the mass hierachy could be accumulated in less than 2 years.

\begin{figure}[h]
	\begin{adjustbox}{max totalsize=.6\linewidth, center}
		\input{files/figures/dune_lbl/mh_sens_exp_nh}
	\end{adjustbox}
	\caption[DUNE's sensitivity to the neutrino mass hierarchy as a function of exposure]{DUNE's sensitivity to the neutrino mass hierarchy as a function of exposure in the case of true normal hierarchy and $\dcp=\pi/2$.}
	\label{fig:mhSensExp}
\end{figure}

One can also see that the addition of the systematics does little here to reduce DUNE's sensitivity to the mass ordering.

\subsection{Charge-parity symmetry violation}
\label{sec:dune_lbl:sensitivities:cpv}

In a similar manner to the mass hierarchy, DUNE's sensitivity to CP-violation in the lepton sector is calculated using the likelihood ratio, $\Delta \chisquare$.
In this case DUNE is attempting to exclude the models where $\dcp = 0$ or $\pi$ (CP-conserving values of \dcp).
Therefore, $\Delta \chisquare = \chi^{2}_{\dcp=0,\pi} - \chi^{2}_{\text{CPV}}$, where $\chi^{2}_{\text{CPV}}$ is the \chisquare value at the \dcp point tested and $\Delta \chisquare_{\dcp=0,\pi} = \min(\Delta \chisquare_{\dcp=0},~\Delta \chisquare_{\dcp=\pi})$.
$\Delta \chisquare_{\dcp=0}$ is evaluated by taking as the Monte Carlo expectation the same oscillation and nuisance parameters as the data but with \dcp fixed at 0.
A similar procedure is used to evaluate $\Delta \chisquare_{\dcp=\pi}$.
One can see that this distribution will necessarily be constrained to fall to $\Delta \chisquare = 0$ at CP conserving values of \dcp.

\citefig{fig:cpvSens} shows the resulting CPV sensitivity as a function of true \dcp.
Here, once again, the square root of $\Delta\chisquare$ has been taken in order to calculate a significance.
\citefigL{fig:cpvSens}, shows the CPV sensitivity in the case of a true normal neutrino mass hierarchy while \citefigR{fig:cpvSens} shows the same distribution in the case of a true inverted mass hierarchy.
The double-humped structure visible in both \citefig{fig:cpvSens} left and right, is a result of the aforementioned constraint on $\Delta\chisquare$ at CP conserving values.

\begin{figure}[h]
	\begin{minipage}[t]{.5\linewidth}
		\begin{adjustbox}{max totalsize=\linewidth, center}
			\input{files/figures/dune_lbl/cpv_sens_nh}
		\end{adjustbox}
	\end{minipage}
	\hfill
	\begin{minipage}[t]{.5\linewidth}
		\begin{adjustbox}{max totalsize=\linewidth, center}
			\input{files/figures/dune_lbl/cpv_sens_ih}
		\end{adjustbox}
	\end{minipage}
	\caption[DUNE sensitivities to CP-violation in the lepton sector as a function of true \dcp.]{DUNE sensitivities to CP-violation in the lepton sector as a function of true \dcp for 7 years of staged running. The black line shows the statistics only case. The blue line shows the case where only the detector systematics are used. The red line shows the case where all systematics are used. Left: True normal neutrino mass hierarchy. Right: True inverted mass hierarchy.}
	\label{fig:cpvSens}
\end{figure}

Looking at \citefig{fig:cpvSens}, one can see that DUNE's sensitivity is slightly better in the case that the true neutrino mass hierarchy is inverted rather than normal.
In the case of the inverted hierarchy, after 7 years of running DUNE will have the potential to discover CPV if the true value of \dcp is near $-\pi/2$ or $\pi/2$ even with all systematics.
However, if the mass hierarchy is normal then DUNE's CPV discovery potential is lower. 
Under this 7 year running plan, DUNE will not reach the crucial $5\sigma$ discovery level when systematics are included. 
However, DUNE will still exceed the $3\sigma$ threshold for many values of \dcp will the suite of systematics.

One interesting point that is observable in \citefig{fig:cpvSens} is that that most of the decrease in sensitivity from the statistics only case occurs when only including the detector systematics.
Although there is a decrease from the red to the blue line upon the inclusion of the flux and cross-section systematics, it is much less substantial than the drop in sensitivity upon the inclusion of just the detector systematics.
It can therefore be assumed that in order for DUNE to reach its full potential, it will be very important to control the detector systematics.
